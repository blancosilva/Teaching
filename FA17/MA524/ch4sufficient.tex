%!TEX root = main.tex

\section{Sufficient Conditions}

It all boils down to a single result.

\begin{theorem}[KKT Sufficient Conditions]\label{theorem:KKTsufficient}\index{Theorem!KKT sufficient conditions}\index{Theorem!Karush-Kuhn-Tucker}
Let $\x \in S$ be a feasible point of the consistent program $(P)$ for which there are multipliers $\lambda_k \geq 0$ ($1\leq k \leq m)$ and $\mu_k \in \field{R}$ ($1\leq k \leq \ell$) satisfying the conditions \ref{item:KKTnecessary1} and \ref{item:KKTnecessary2} of Theorem \ref{theorem:KKTnecessary}. If $f$ is pseudo-convex, $g_k$ is quasi-convex for all $1\leq k \leq m$, and $h_k$ is linear for all $1\leq k \leq \ell$, then $\x$ is a global optimal solution of $(P)$.
\end{theorem}

\begin{example}
We saw that the point $(0,0)$ satisfies the KKT conditions for the super-consistent convex program $(P)$ in Example \ref{example:feasibleP1}.  As a consequence of Theorems \ref{theorem:FritzJohn} and \ref{theorem:KKTsufficient}, this point must be the optimal global minimum of $(P)$.

We also saw that the point $(2,1)$ satisfies the KKT conditions for the program $(P)$ in Example \ref{example:feasibleP3}.  It is not hard to see that this program is super-consistent, $f$ is pseudo-convex, $g_1$ and $g_2$ are quasi-convex, and $h_1$ is linear.  By virtue of Theorems \ref{theorem:KKTnecessary} and \ref{theorem:KKTsufficient}, the point $(2,1)$ must be the optimal solution of $(P)$.
\end{example}

\section*{Key Examples}
In the following section we are going to use the KKT conditions to address the characterization of optimal solutions of generic programs. 

\begin{example}
Let $\boldsymbol{Q}$ be a symmetric $d \times d$ square matrix.  Consider the associated quadratic form $\quadratic{Q}(\x)$.  We wish to find the global \emph{maximum} over all points of this function in the unit ball $\field{B}_d = \{ \x \in \field{R}^d : \norm{\x} \leq 1 \}$.

An equivalent program $(P)$ is thus defined with $f(\x) = -\quadratic{Q}(\x)$ as its objective function, and a single inequality constraint $g_1(\x) = \norm{\x}^2-1$. This is trivially a super-consistent program with a convex inequality constraint.  Checking the KKT conditions to look for the optimal solution is thus justified under the hypothesis of Theorem \ref{theorem:Slater}.  Notice that
\begin{align*}
\transpose{\gradient{f}(\x)} &= -2 \boldsymbol{Q} \transpose{\x}, \\
\gradient{g_1}(\x) &= 2\x;
\end{align*}
therefore, the KKT conditions request the search for $\x \in \field{B}_d$ and $\lambda \geq 0$ so that $\lambda \big(1-\norm{\x}^2 \big)=0$ and $-2\boldsymbol{Q} \transpose{\x} + 2\lambda\transpose{\x} = \transpose{\boldsymbol{0}}$.  

It must be $\norm{\x}=1$ by the first condition.  The second condition states that $\x$ must be an eigenvector of $\boldsymbol{Q}$ with eigenvalue $\lambda$: $\boldsymbol{Q} \transpose{\x} = \lambda \transpose{\x}$.  The value of the objective function in this case is $f(\x) = -\quadratic{Q}(\x) = -\x \boldsymbol{Q} \transpose{\x} = -\lambda \norm{\x}^2= -\lambda$.  In order to obtain the requested global minimum value (different than zero), $\lambda$ has to be the largest non-negative eigenvalue of $\boldsymbol{Q}$, and $\x$ its corresponding normalized eigenvector.
\end{example}

\begin{example}
A simple case of the previous example: Set $\boldsymbol{Q} = \big[ \begin{smallmatrix} 1 & 3 \\ 3 & 1 \end{smallmatrix}\big]$.  The eigenvalues of $\boldsymbol{Q}$ are $-2$ and $4$, and therefore the maximum of the associated quadratic form $\quadratic{Q}(x,y) = x^2+y^2+6xy$ over the ball $x^2+y^2\leq 1$ happens at the (normalized) solution of the system
\begin{equation*}
\begin{bmatrix} 1 & 3 \\ 3 & 1 \end{bmatrix} \begin{bmatrix} x \\ y \end{bmatrix} = 4\begin{bmatrix} x \\ y \end{bmatrix}.
\end{equation*}
This gives the points $\pm(\sqrt{2}/2, \sqrt{2}/2)$.
\end{example}

\begin{example}
Let $\x_0 \in \field{R}^d\setminus\{\boldsymbol{0}\}$ and $r>0$.  Find the point on the sphere of radius $r$, $\field{S}_d=\{ \x \in \field{R}^d: \norm{\x}=r \}$ that is closer to $\x_0$. 

We may write a super-consistent convex program to solve this optimization problem by using $f(\x)=\norm{\x-\x_0}^2$ as objective function, and one equality constraint $h_1(\x)=\norm{\x}^2-r^2$.  With this choice, we are well within the hypothesis of Theorems \ref{theorem:KKTnecessary} and \ref{theorem:KKTsufficient}.  The KKT conditions request $\mu \in \field{R}$ and a point $\x \in \field{R}^d$ with $\norm{\x} = r$ so that
\begin{equation*} 
\gradient{f}(\x) + \mu\gradient{h_1}(\x) = \boldsymbol{0},
\end{equation*}
This gives $2(\x-\x_0)+2\mu\x = \boldsymbol{0}$, or equivalently, $(1+\mu)\x = \x_0$.

It must be $\mu = -1+\norm{\x_0}/r$.  We have then two cases:
\begin{enumerate}
	\item If $\norm{\x_0}=r$, then $\mu=0$ and $\x=\x_0$ is the only solution.
	\item If $\norm{\x_0} \neq r$ (the point $\x_0$ is not on the sphere), then $\x = r\x_0/\norm{\x_0}$.
\end{enumerate}
\end{example}

\begin{example}\index{Linear map}
Find the minimum value of a (real-valued) linear map over the unit ball.

Given $\boldsymbol{a} \in \field{R}^d\setminus\{ \boldsymbol{0}\}$, consider the corresponding linear map $\boldsymbol{L}(\x) = \langle \boldsymbol{a}, \x \rangle$.  We wish to find the minimum value of $\boldsymbol{L}$ over all points in the unit ball $\field{B}_d = \{ \x \in \field{R}^d : \norm{\x} \leq 1 \}$.

An equivalent program $(P)$ is defined with $\boldsymbol{L}$ as its objective function and $g_1(\x) = \norm{\x}^2-1$. This is a super-consistent convex program.  Checking the KKT conditions is justified under the hypothesis of Theorem \ref{theorem:KKTnecessary}. Notice that
\begin{align*}
\gradient{\boldsymbol{L}}(\x) &= \boldsymbol{a}, \\
\gradient{g_1}(\x) &= 2\x;
\end{align*}
therefore, the KKT conditions request the search for $\x \in \field{B}_d$ and $\lambda \geq 0$ so that $\lambda \big( \norm{\x}^2-1 \big)=0$ and $\boldsymbol{a}+2\lambda\x=\boldsymbol{0}$.

This first condition imposes $\norm{\x}=1$.  The second condition requires $\x = -\boldsymbol{a}/(2\lambda)$.  These two put together imply that it must be $\lambda = -\norm{\boldsymbol{a}}/2$, and hence $\x = -\boldsymbol{a}/\norm{\boldsymbol{a}}$.
\end{example}