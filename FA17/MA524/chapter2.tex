%!TEX root = notes.tex

\chapter{Existence and Characterization of Extrema}\label{chapter:existenceCharacterization}

In this chapter we will study different properties of functions and domains that guarantee existence of extrema. Once we have them, we explore characterization of those points.  We start with a reminder of the definition of continuous and differentiable functions.

\begin{definition}\label{def:continuous}
We say that a real-valued function $f\colon D \to \field{R}$ is continuous at a point $\x_0 \in D$ if for all $\varepsilon > 0$ there exists $\delta > 0$ so that for all $\x \in D$ satisfying $\norm{\x-\x_0}<\delta$, it is $\abs{ f(\x) - f(\x_0) } < \varepsilon$.  
\end{definition}

\begin{example}
Let $f\colon \field{R}^2 \to \field{R}$ be given by
\begin{equation*}
f(x,y) = \begin{cases}
\frac{2xy}{x^2+y^2}, &(x,y) \neq (0,0) \\
0, &(x,y)=(0,0)
\end{cases}
\end{equation*}
This function is trivially continuous at any point $(x,y)\neq(0,0)$.  However, it fails to be continuous at the origin.  Notice how we obtain different values as we approach $(0,0)$ through different generic lines $y=mx$ with $m \in \field{R}$:
\begin{equation*}
\lim_{x\to 0} f(x,mx) = \lim_{x \to 0} \frac{2mx^2}{(1+m^2)x^2} = \frac{2m}{1+m^2}.
\end{equation*}
\end{example}

\begin{definition}\label{def:differentiable}
A real-valued function $f$ is said to be \emph{differentiable} at $\x_0$ if there exists a \emph{linear function} $J\colon \field{R}^d \to \field{R}$ so that 
\begin{equation*}
\lim_{\boldsymbol{h} \to \boldsymbol{0}} \frac{\abs{f(\x_0+h)-f(\x_0)-J(\boldsymbol{h})}}{\norm{\boldsymbol{h}}} = 0
\end{equation*}
\end{definition}

\begin{remark}
A function is said to be \emph{linear} if it satisfies $J(\x+\lambda\y) = J(\x) + \lambda J(\y)$ for all $\x, \y \in \field{R}^d$, $\lambda \in \field{R}$.  For each real-valued linear function $J \colon \field{R}^d \to \field{R}$ there exists $\boldsymbol{a} \in \field{R}^d$ so that $J(\x) = \langle \boldsymbol{a} , \x \rangle$ for all $\x \in \field{R}^d$.  For this reason, the graph of a linear function is a hyperplane in $\field{R}^d$.
\end{remark}

\begin{remark}
For any differentiable real-valued function $f$ at a point $\x$ of its domain, the corresponding linear function in the definition above guarantees a tangent hyperplane to the graph of $f$ at $\x$.  
\end{remark}
 
\begin{example}\label{example:derivatives}
Consider a real-valued function $f\colon \field{R} \to \field{R}$ of a real variable. To prove differentiability at a point $x_0$, we need a linear function: $J(h)=ah$ for some $a\in \field{R}$. Notice how in that case, 
\begin{equation*}
\frac{\abs{f(x_0+h)-f(x_0)-J(h)}}{\abs{h}} = \left\lvert \frac{f(x_0)-f(x_0)}{h} - a \right\lvert;
\end{equation*}
therefore, we could pick $a = \lim_{h\to 0} h^{-1}\big( f(x_0+h) - f(x_0) \big)$---this is the definition of derivative we learned in Calculus: $a=f'(x_0)$
\end{example}

A \emph{friendly} version of the differentiability of real-valued functions comes with the next result (see, e.g.~\cite[p.818]{finney2001thomas})::s
\begin{theorem}\label{theorem:partialgivesDerivative}
If the partial derivatives $\frac{\partial f}{\partial x_1}, \dotsc, \frac{\partial f}{\partial x_d}$ of a real-valued function $f \colon \field{R}^d \to \field{R}$ are continuous on an open region $G \subseteq \field{R}^d$, then $f$ is differentiable at every point of $\field{R}$.
\end{theorem}

\begin{example}\label{example:gradient}
Let $f\colon \field{R}^d \to \field{R}$.  To prove that $f$ is differentiable at a point $\x_0 \in \field{R}^d$ we need a linear function $J(h) = \langle \boldsymbol{a}, h \rangle$ for some $\boldsymbol{a} \in \field{R}^d$.  From our Vector Calculus classes we found out that under the conditions of Theorem \ref{theorem:partialgivesDerivative} we may use
\begin{equation*}
\boldsymbol{a} = \gradient{f}(\x_0)= \bigg( \frac{\partial f}{\partial x_1}(\x_0), \dotsc, \frac{\partial f}{\partial x_d}(\x_0) \bigg).
\end{equation*}
\end{example}

\section{Functions on compact domains}
The existence of global maxima and minima is guaranteed for continuous functions over compact sets thanks to the following two basic results:

\begin{theorem}[Bounded Value Theorem]\label{theorem:BVT}
The image $f(K)$ of a continuous real-valued function $f \colon \field{R}^d \to \field{R}$ on a compact set $K$ is bounded: there exists $M>0$ so that $\abs{ f(\x) } \leq M$ for all $\x \in K$.
\end{theorem}

\begin{theorem}[Extreme Value Theorem]\label{theorem:EVT}
A continuous real-valued function $f \colon K \to \field{R}$ on a compact set $K \subset \field{R}^d$ takes on minimal and maximal values on $K$.
\end{theorem}

\section{Functions on unbounded domains}
Extra restrictions must be applied to the behavior of $f$ in this case, if we want to guarantee the existence of extrema. We consider first an obvious example based on Example \ref{example:CoerciveFunctions}.

\begin{definition}[Coercive functions]\label{def:coerciveFunctions}
A continuous real-valued function $f$ is said to be \emph{coercive} if for all $M>0$ there exists $R=R(M)>0$ so that $f(\x)\geq M$ if $\norm{\x}\geq R$.
\end{definition}

\begin{remark}
This is equivalent to the limit condition  
\begin{equation*}
\lim_{\norm{\x}\to \infty} f(\x) = +\infty.
\end{equation*}
\end{remark}

\begin{example}\label{example:CoerciveFunctionsGeneral}
We saw in Example \ref{example:CoerciveFunctions} how even-degree polynomials with positive leading coefficients are coercive, and how this helped guarantee the existence of a minimum.

We must be careful assessing coerciveness of polynomials in higher dimension. Consider for example $p_2(x,y) = x^2 - 2xy + y^2$.  Note how $p_2(x,x)=0$ for any $x \in \field{R}$, which proves $p_2$ is not coercive.

To see that the polynomial $p_4(x, y) = x^4 + y^4 - 3xy$ is coercive, we start by factoring the leading terms:
\begin{equation*}
x^4 + y^4 - 3xy = (x^4 + y^4) \bigg( 1 - \frac{3xy}{x^4 + y^4} \bigg)
\end{equation*}
Assume $r>1$ is large, and that $x^2+y^2 = r^2$.  We have then
\begin{align*}
x^4 + y^4 &\geq \frac{r^4}{2} \qquad\text{(Why?)} \\
% Do x=rcos(theta) y=rsin(theta) and note x^4+y^4=r^4(cos^(theta)+sin^4(theta))
 \abs{x y} &\leq \frac{r^2}{2} \qquad\text{(Why?)}
% Same x,y, to see that xy = r^2cos(theta)sin(theta) = r^2 sin(2theta)/2
\end{align*}
therefore, 
\begin{align*}
\frac{3xy}{x^4 + y^4} &\leq \frac{3}{r^2} \\
1 - \frac{3xy}{x^4 + y^4} &\geq 1 - \frac{3}{r^2} \\
(x^4 + y^4) \bigg( 1 - \frac{3x y}{x^4 + y^4} \bigg) &\geq \frac{r^2(r^2-3)}{2}
\end{align*} 
We can then conclude that given $M>0$, if $x^2+y^2 \geq \tfrac{1}{2} \big( 3+\sqrt{9+8M} \big)$, then $f(x,y) \geq M$.
\end{example}

\begin{theorem}\label{theorem:CoerciveFunctions}
Coercive functions always have a global minimum.
\end{theorem}
\begin{proof}
Since $f$ is coercive, there exists $r>0$ so that $f(\x) > f(\boldsymbol{0})$ for all $\x$ satisfying $\norm{\x}>r$.  On the other hand, consider the closed ball $K_r = \{ \x \in \field{R}^2 : \norm{\x} \leq r \}$.  The continuity of $f$ guarantees a global minimum $\xstar \in K_r$ with $f(\xstar) \leq f(\boldsymbol{0})$.  It is then $f(\xstar) \leq f(\x)$ for all $\x \in \field{R}^d$ trivially.
\end{proof}

\section{Convex functions}
\begin{definition}[Convex Sets]\label{def:convexSets}
A subset $C \subseteq \field{R}^d$ is said to be \emph{convex} if for every $\x, \y \in C$, and every $\lambda \in [0,1]$, the point $\lambda \y + (1-\lambda) \x$ is also in $C$.
\end{definition}

\begin{definition}[Convex Functions]\label{def:ConvexFunctions}
Given a convex set $C \subseteq \field{R}^d$, we say that a real-valued function $f \colon C \to \field{R}$ is \emph{convex} if 
\begin{equation*}
f\big(\lambda \y + (1-\lambda)\x \big) \leq \lambda f(\y) + (1-\lambda) f(\x)
\end{equation*}
If instead we have $f\big(\lambda \x + (1-\lambda)f(\y)\big) < \lambda f(\x) + (1-\lambda) f(\y)$ for $0<\lambda<1$, we say that the function is \emph{strictly convex}.  A function $f$ is said to be \emph{concave} (resp.~\emph{strictly concave}) if $-f$ is convex (resp.~strictly convex).
\end{definition}
Convex functions have many pleasant properties:
\begin{theorem}\label{theorem:ConvexIsContinuous}
Convex functions are continuous
\end{theorem}

\begin{theorem}
Let $f\colon C \to \field{R}$ be a real-valued convex function defined on a convex set $C \subseteq \field{R}^d$.  If $\lambda_1, \dotsc, \lambda_n$ are nonnegative numbers satisfying $\lambda_1 + \dotsb + \lambda_n = 1$ and $\x_1, \dotsc, x_n$ are $n$ different points in $C$, then
\begin{equation*}
f\big( \lambda_1 \x_1 + \dotsb + \lambda_n x_n \big) \leq \lambda_1 f(\x_1) + \dotsb + \lambda_n f(\x_n).
\end{equation*}
\end{theorem}

\begin{theorem}\label{theorem:convexAboveTangentHyperplane}
If $f\colon C \to \field{R}$ is a function on a convex set $C \subseteq \field{R}^d$ with continuous first partial derivatives on $C$, then
\begin{enumerate}
	\item $f$ is convex if and only if for all $\x, \y \in C$,
	\begin{equation*}
	f(\x) + \langle \gradient{f}(\x), \y - \x \rangle \leq f(\y).
	\end{equation*}
	\item $f$ is strictly convex if for all $\x \neq \y \in C$,
	\begin{equation*}
	f(\x) + \langle \gradient{f}(\x), \y - \x \rangle < f(\y).
	\end{equation*}
\end{enumerate}
\end{theorem}

\begin{remark}
Theorem \ref{theorem:convexAboveTangentHyperplane} implies that the graph of any (strictly) convex function always lies over the tangent hyperplane at any point of the graph.
\begin{figure}[ht!]
\begin{tabular}{cc}
\includegraphics[width=0.5\linewidth]{convexFunction1.png} &
\includegraphics[width=0.5\linewidth]{convexFunction2.png}
\end{tabular}
\caption{Convex Functions.}
\label{figure:convexFunction}
\end{figure}
\end{remark}

Another useful characterization of convex functions.
\begin{theorem}
Suppose that $f\colon C \to \field{R}$ is a function with second partial derivatives on an open convex set $C \subseteq \field{R}^d$.  If the Hessian is positive semidefinite (resp.~positive definite) on $C$, then $f$ is convex (resp.~strictly convex).
\end{theorem}

% \begin{theorem}
% Any local minimum of a convex function is also a global minimum.  Any local minimum of a strictly convex function is the unique strict global minimum.
% \end{theorem}